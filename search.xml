<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[python中的pythonpath]]></title>
    <url>%2F2025%2F01%2F01%2Fpython%E4%B8%AD%E7%9A%84pythonpath%2F</url>
    <content type="text"><![CDATA[Python中的PYTHONPATH 这个配置能帮助python解释器定位项目根目录 自己编写一个能自动获取项目路径的工具 然后根据所在系统生成环境初始化脚本工具代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# -*- coding: utf-8 -*-import osimport sysfrom typing import Dictfrom pathlib import Pathdef init_config(): pythonpath = os.path.abspath(Path(__file__).absolute().parent) logs_name = 'logs' log_path = os.path.join(pythonpath,logs_name) config_data = &#123; 'PYTHONPATH': pythonpath, 'LOG_PATH': log_path &#125; raw_data = '' for k, v in config_data.items(): print(f'&#123;k&#125;: &#123;v&#125;') raw_data += f'&#123;k&#125;=&#123;v&#125;\n' with open('.env','w',encoding='utf-8') as f: f.write(raw_data) return config_datadef win32_set_env(data: Dict[str,str|None]): file = '' for k, v in data.items(): file += f'@set &#123;k&#125;=&#123;v&#125;\n' file += '@echo WIN32 ENV SET DONE' with open('start_win32_env.bat','w',encoding='utf-8') as f: f.write(file)def linux_set_env(data: Dict[str,str|None]): file = '' for k, v in data.items(): file += f'export &#123;k&#125;=&#123;v&#125;\n' file += 'echo LINUX ENV SET DONE' with open('start_linux_env.sh','w',encoding='utf-8') as f: f.write(file)def main(): config_data = init_config() platform = sys.platform if platform == 'win32': win32_set_env(config_data) elif platform == 'linux': linux_set_env(config_data)if __name__ == '__main__': print(' WELCOME USE ENV INIT '.center(60,'=')) main()]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[整理两个python工具]]></title>
    <url>%2F2024%2F01%2F01%2F%E6%95%B4%E7%90%86%E4%B8%A4%E4%B8%AApython%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[整理两个Python工具 仅供自己使用 Log封装工具123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673# -*- coding: utf-8 -*-import loggingimport datetime, reimport time, randomimport osimport ctypesfrom logging.handlers import TimedRotatingFileHandler, BaseRotatingHandlerfrom pathlib import Pathimport traceback# 多进程或者多线程日志模块try: import codecsexcept ImportError: codecs = None# 支持多进程的TimeRotatingFileHandlerclass MultiProcessHandler(logging.FileHandler): def __init__(self, filename, when='D', backupCount=0, encoding='utf-8', delay=False, log_path='logs'): """ filename 日志文件名,when 时间间隔的单位,backupCount 保留文件个数 delay 是否开启 OutSteam缓存 True 表示开启缓存,OutStream输出到缓存,待缓存区满后,刷新缓存区,并输出缓存数据到文件。 False表示不缓存,OutStrea直接输出到文件 """ self.prefix = filename self.backupCount = backupCount self.when = when.upper() # 正则匹配 年-月-日 # 正则写到这里就对了 self.extMath = r"^\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125;" # S 每秒建立一个新文件 # M 每分钟建立一个新文件 # H 每天建立一个新文件 # D 每天建立一个新文件 self.when_dict = &#123; 'S': "%Y-%m-%d-%H-%M-%S", 'M': "%Y-%m-%d-%H-%M", 'H': "%Y-%m-%d-%H", 'D': "%Y-%m-%d" &#125; # 日志文件日期后缀 self.suffix = self.when_dict.get(when) # 源码中self.extMath写在这里 # 这个正则匹配不应该写到这里,不然非D模式下 会造成 self.extMath属性不存在的问题 # 不管是什么模式都是按照这个正则来搜索日志文件的。 # if self.when == 'D': # 正则匹配 年-月-日 # self.extMath = r"^\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125;" if not self.suffix: raise ValueError(u"指定的日期间隔单位无效: %s" % self.when) # 拼接文件路径 格式化字符串 self.filefmt = os.path.join(log_path, "%s.%s.log" % (self.prefix, self.suffix)) # 使用当前时间,格式化文件格式化字符串 self.filePath = datetime.datetime.now().strftime(self.filefmt) # 获得文件夹路径 _dir = os.path.dirname(self.filefmt) try: # 如果日志文件夹不存在,则创建文件夹 if not os.path.exists(_dir): os.makedirs(_dir) except Exception: print(u"创建文件夹失败") print(u"文件夹路径：" + self.filePath) pass if codecs is None: encoding = None # 调用FileHandler logging.FileHandler.__init__(self, self.filePath, 'a+', encoding, delay) def shouldChangeFileToWrite(self): """更改日志写入目的写入文件 return True 表示已更改,False 表示未更改""" # 以当前时间获得新日志文件路径 _filePath = datetime.datetime.now().strftime(self.filefmt) # 新日志文件日期 不等于 旧日志文件日期,则表示 已经到了日志切分的时候 # 更换日志写入目的为新日志文件。 # 例如 按 天 （D）来切分日志 # 当前新日志日期等于旧日志日期,则表示在同一天内,还不到日志切分的时候 # 当前新日志日期不等于旧日志日期,则表示不在 # 同一天内,进行日志切分,将日志内容写入新日志内。 if _filePath != self.filePath: self.filePath = _filePath return True return False def doChangeFile(self): """输出信息到日志文件,并删除多于保留个数的所有日志文件""" # 日志文件的绝对路径 self.baseFilename = os.path.abspath(self.filePath) # stream == OutStream # stream is not None 表示 OutStream中还有未输出完的缓存数据 if self.stream: # self.stream.flush() # flush close 都会刷新缓冲区，flush不会关闭stream，close则关闭stream self.stream.close() # 关闭stream后必须重新设置stream为None，否则会造成对已关闭文件进行IO操作。 self.stream = None # delay 为False 表示 不OutStream不缓存数据 直接输出 # 所有,只需要关闭OutStream即可 if not self.delay: # 这个地方如果关闭colse那么就会造成进程往已关闭的文件中写数据，从而造成IO错误 # delay == False 表示的就是 不缓存直接写入磁盘 # self.stream.close() # 我们需要重新在打开一次stream self.stream = self._open() # 删除多于保留个数的所有日志文件 if self.backupCount &gt; 0: for s in self.getFilesToDelete(): os.remove(s) def getFilesToDelete(self): """获得过期需要删除的日志文件""" # 分离出日志文件夹绝对路径 # split返回一个元组（absFilePath,fileName) # 例如：split('I:\ScripPython\char4\mybook\util\logs\mylog.2017-03-19） # 返回（I:\ScripPython\char4\mybook\util\logs, mylog.2017-03-19） # _ 表示占位符,没什么实际意义, dirName, _ = os.path.split(self.baseFilename) fileNames = os.listdir(dirName) result = [] # self.prefix 为日志文件名 列如：mylog.2017-03-19 中的 mylog # 加上 点号 . 方便获取点号后面的日期 prefix = self.prefix + '.' plen = len(prefix) for fileName in fileNames: if fileName[:plen] == prefix: # 日期后缀 mylog.2017-03-19 中的 2017-03-19 suffix = fileName[plen:] # 匹配符合规则的日志文件,添加到result列表中 if re.compile(self.extMath).match(suffix): result.append(os.path.join(dirName, fileName)) result.sort() # 返回 待删除的日志文件 # 多于 保留文件个数 backupCount的所有前面的日志文件。 if len(result) &lt; self.backupCount: result = [] else: result = result[:len(result) - self.backupCount] return result def emit(self, record): """发送一个日志记录 覆盖FileHandler中的emit方法,logging会自动调用此方法""" try: if self.shouldChangeFileToWrite(): self.doChangeFile() logging.FileHandler.emit(self, record) except (KeyboardInterrupt, SystemExit): raise except: self.handleError(record)class MyTimedRotatingFileHandler(TimedRotatingFileHandler): def __init__(self, filename, when='d', interval=1, backupCount=0, encoding=None, delay=False, utc=False, atTime=None, errors=None): super().__init__(filename=filename, when=when, interval=interval, backupCount=backupCount, encoding=encoding, delay=delay, utc=utc, atTime=atTime, errors=errors) filename = self.baseFilename if os.path.exists(filename): t = os.stat(filename).st_ctime else: t = int(time.time()) self.rolloverAt = self.computeRollover(t) # rolloverAtFmt = datetime.datetime.fromtimestamp(self.rolloverAt).strftime('%Y-%m-%d %H:%M:%S') # print(f'log rolloverAt ===&gt; &#123;self.rolloverAt&#125; rolloverAtFmt ===&gt; &#123;rolloverAtFmt&#125;')class DailyRotatingFileHandler(BaseRotatingHandler): """ 同`logging.TimedRotatingFileHandler`类似，不过这个handler： - 可以支持多进程 - 只支持自然日分割 - 暂不支持UTC """ def __init__(self, filename, backupCount=0, encoding=None, delay=False, utc=False, log_path='logs', **kwargs): self.backup_count = backupCount self.utc = utc self.suffix = "%Y-%m-%d" self.base_log_path = Path(os.path.join(log_path, filename)) self.base_filename = self.base_log_path.name self.current_filename = self._compute_fn() self.current_log_path = self.base_log_path.with_name(self.current_filename) BaseRotatingHandler.__init__(self, filename, 'a', encoding, delay) def shouldRollover(self, record): """ 判断是否该滚动日志，如果当前时间对应的日志文件名与当前打开的日志文件名不一致，则需要滚动日志 """ if self.current_filename != self._compute_fn(): return True return False def doRollover(self): """ 滚动日志 """ # 关闭旧的日志文件 if self.stream: self.stream.close() self.stream = None # 计算新的日志文件 self.current_filename = self._compute_fn() self.current_log_path = self.base_log_path.with_name(self.current_filename) # 打开新的日志文件 if not self.delay: self.stream = self._open() # 删除过期日志 self.delete_expired_files() def _compute_fn(self): """ 计算当前时间对应的日志文件名 """ return self.base_filename + "." + time.strftime(self.suffix, time.localtime()) def _open(self): """ 打开新的日志文件，同时更新base_filename指向的软链，修改软链不会对日志记录产生任何影响 """ if self.encoding is None: stream = open(str(self.current_log_path), self.mode) else: stream = codecs.open(str(self.current_log_path), self.mode, self.encoding) # 删除旧的软链 if self.base_log_path.exists(): try: # 如果base_log_path不是软链或者指向的日志文件不对，则先删除该软链 if not self.base_log_path.is_symlink() or os.readlink(self.base_log_path) != self.current_filename: os.remove(self.base_log_path) except OSError: pass # 建立新的软链 try: os.symlink(self.current_filename, str(self.base_log_path)) except OSError: pass return stream def delete_expired_files(self): """ 删除过期的日志 """ if self.backup_count &lt;= 0: return file_names = os.listdir(str(self.base_log_path.parent)) result = [] prefix = self.base_filename + "." plen = len(prefix) for file_name in file_names: if file_name[:plen] == prefix: suffix = file_name[plen:] if re.match(r"^\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125;(\.\w+)?$", suffix): result.append(file_name) if len(result) &lt; self.backup_count: result = [] else: result.sort() result = result[:len(result) - self.backup_count] for file_name in result: os.remove(str(self.base_log_path.with_name(file_name)))class LogPrint: def __init__(self): pass def info(self, msg): print(msg) def error(self, msg): print(msg) def debug(self, msg): print(msg) def printErrorLog(self, e): print("Error Info: " + str(e)) print("Error File: " + str(e.__traceback__.tb_frame.f_globals["__file__"])) print("Error Row: " + str(e.__traceback__.tb_lineno)) print(e.args) print('Error Traceback:\n%s' % traceback.format_exc())class LogTool: def __init__(self, log_name='info', name='', log_path='logs', path='', randFlag=False): self.LOG_FORMAT = "%(asctime)s - %(levelname)s - %(message)s" self.DATE_FORMAT = "%Y-%m-%d %H:%M:%S %a" if name: log_name = name if path: log_path = path if randFlag: log_name = '&#123;&#125;_&#123;&#125;&#123;&#125;'.format(log_name, int(time.time() * 1000), random.randint(100000, 999999)) self.log_name = log_name self.log_path = log_path self.log_level = logging.INFO self.logger = logging.getLogger(log_name) self.logger.root.setLevel(self.log_level) # Windows CMD命令行 字体颜色定义 text colors self.FOREGROUND_WHIT = 0x0f self.FOREGROUND_GREEN = 0xf2 # green. # 常规日志 def init_log(self, new_log_flag=False): try: if not os.path.exists(self.log_path): os.makedirs(self.log_path) except Exception as e: pass if not self.logger.handlers: formatter = logging.Formatter(fmt=self.LOG_FORMAT, datefmt=self.DATE_FORMAT) # 输出到console consoleHandler = logging.StreamHandler() consoleHandler.setLevel(self.log_level) consoleHandler.setFormatter(formatter) self.logger.addHandler(consoleHandler) # 创建 TimedRotatingFileHandler,并设置文件名、滚动间隔和保留日志文件个数 fname = '%s.log' % self.log_name logFile = os.path.join(self.log_path, fname) # fileHandler = TimedRotatingFileHandler(filename=logFile,when='d',interval=1,backupCount=3,encoding='utf-8') if new_log_flag: fileHandler = MyTimedRotatingFileHandler(filename=logFile, when='MIDNIGHT', interval=1, backupCount=3, encoding='utf-8') else: fileHandler = TimedRotatingFileHandler(filename=logFile, when='MIDNIGHT', interval=1, backupCount=3, encoding='utf-8') # MIDNIGHT 按照自然日分割日志 # fileHandler = TimedRotatingFileHandler(filename=logFile,when='MIDNIGHT',interval=1,backupCount=3,encoding='utf-8') # fileHandler.suffix = '%Y-%m-%d.log' # fileHandler.encoding = 'utf8' fileHandler.setLevel(self.log_level) fileHandler.setFormatter(formatter) self.logger.addHandler(fileHandler) return self.logger # 多进程或者多线程日志 def init_multi_process_log(self): try: if not os.path.exists(self.log_path): os.makedirs(self.log_path) except Exception as e: pass if not self.logger.handlers: formatter = logging.Formatter(fmt=self.LOG_FORMAT, datefmt=self.DATE_FORMAT) # 输出到console consoleHandler = logging.StreamHandler() consoleHandler.setLevel(self.log_level) consoleHandler.setFormatter(formatter) self.logger.addHandler(consoleHandler) fileHandler = MultiProcessHandler(self.log_name, 'D', 3, log_path=self.log_path) fileHandler.setFormatter(formatter) fileHandler.setLevel(self.log_level) self.logger.addHandler(fileHandler) return self.logger def init_mpt_log(self): try: if not os.path.exists(self.log_path): os.makedirs(self.log_path) except Exception as e: pass if not self.logger.handlers: formatter = logging.Formatter(fmt=self.LOG_FORMAT, datefmt=self.DATE_FORMAT) # 输出到console consoleHandler = logging.StreamHandler() consoleHandler.setLevel(self.log_level) consoleHandler.setFormatter(formatter) self.logger.addHandler(consoleHandler) fileHandler = DailyRotatingFileHandler(self.log_name, 3, 'utf-8') fileHandler.setFormatter(formatter) fileHandler.setLevel(self.log_level) self.logger.addHandler(fileHandler) return self.logger def close_log(self): logging.shutdown() def printErrorLog(self, e): log = self.init_log() log.error("Error Info: " + str(e)) log.error("Error File: " + str(e.__traceback__.tb_frame.f_globals["__file__"])) log.error("Error Row: " + str(e.__traceback__.tb_lineno)) log.error(e.args) log.error('Error Traceback:\n%s' % traceback.format_exc()) def set_cmd_text_color(self, color): # 字体颜色定义 ,关键在于颜色编码，由2位十六进制组成，分别取0~f，前一位指的是背景色，后一位指的是字体色 # 由于该函数的限制，应该是只有这16种，可以前景色与背景色组合。也可以几种颜色通过或运算组合，组合后还是在这16种颜色中 STD_INPUT_HANDLE = -10 STD_OUTPUT_HANDLE = -11 STD_ERROR_HANDLE = -12 handle = ctypes.windll.kernel32.GetStdHandle(STD_OUTPUT_HANDLE) Bool = ctypes.windll.kernel32.SetConsoleTextAttribute(handle, color) return Bool # reset white def resetColor(self, color): self.set_cmd_text_color(color) def sqlInfo(self, mess): self.resetColor(self.FOREGROUND_GREEN) self.init_log().info(str(mess)) self.resetColor(self.FOREGROUND_WHIT) def get_curr_log(self): app_log = os.path.join(self.log_path, self.log_name) if os.path.exists(app_log): return app_log _path = Path(app_log) fname = _path.stem ext = _path.suffix[1:] log_path = _path.parent # hard_link = '_curr_' hard_link = '' fmt = datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d') log_hard_link = '.'.join([fname, hard_link, ext]) log_name = '.'.join([fname, fmt, ext]) self.log_data(log_path=log_path, source=log_name, target=log_hard_link) return os.path.join(log_path, log_hard_link) def log_data(self, source='', target=''): source_path = os.path.join(self.log_path, source) if not os.path.exists(source_path): return False target_path = os.path.join(self.log_path, target) if os.path.exists(target_path): f_stat = os.stat(target_path) if time.time() - f_stat.st_mtime &gt;= 5: if os.path.exists(target_path): os.unlink(target_path) os.link(source_path, target_path) if not os.path.exists(target_path): os.link(source_path, target_path)'''file.seek(offset,whence)offset -- 开始的偏移量，也就是代表需要移动偏移的字节数whence：可选，默认值为 0。给offset参数一个定义，表示要从哪个位置开始偏移；0代表从文件开头开始算起，1代表从当前位置开始算起，2代表从文件末尾算起file.tell()返回文件的当前位置，即文件指针当前位置'''# 获取日志末尾指定行数def show_logs_foot(log_path, n, block=-4096, del_space=False): if not os.path.exists(log_path): return '' with open(log_path, 'rb') as f: # 指针移动到文件末尾 f.seek(0, 2) # 返回指针当前位置 log_size = f.tell() # print('fileSize: &#123;&#125;'.format(log_size)) # 如果文件为空则返回空 if log_size &lt; 1: return '' while True: # 判断offset是否大于文件字节数,是则读取所有行,并返回 if log_size &gt;= abs(block): # 将指针移动到倒数的字节数位置 f.seek(block, 2) # 读取这个范围的文本 data = f.readlines() # 排除空白字符 if del_space: data_t = [t for t in data[1:] if t.strip()] data_t_size = len(data_t) if data_t_size &gt; n: return data_t[-n:] if abs(block) &lt; log_size: block *= 2 continue else: return data_t if len(data) &gt; n: return data[-n:] else: block *= 2 else: # 将指针移动至文件开头 f.seek(0, 0) # 读取这个范围的文本 data = f.readlines() # 排除空白字符 if del_space: data_t = [t for t in data if t.strip()] return data_t return data# 获取日志头部指定行数def show_logs_head(log_path, n, block=4096, del_space=False): if not os.path.exists(log_path): return '' with open(log_path, 'rb') as f: # 指针移动到文件末尾 f.seek(0, 2) # 返回指针当前位置 log_size = f.tell() # print('fileSize: &#123;&#125;'.format(log_size)) # 如果文件为空则返回空 if log_size &lt; 1: return '' # 将指针移动到文件开头 f.seek(0, 0) data = [] data_t = [] while True: if f.tell() &gt;= log_size: if del_space: return data_t return data data.append(f.readline()) if len(data) &gt;= n: # 排除空白字符 if del_space: data_t = [t for t in data if t.strip()] data_t_size = len(data_t) if data_t_size &gt;= n: return data_t[:n + 1] else: continue return datadef get_current_log_name(log_path): _path = Path(log_path) fname = _path.stem ext = _path.suffix[1:] log_path = _path.parent hard_link = '_curr_' # hard_link = '' fmt = datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d') log_hard_link = '.'.join([fname,hard_link,ext]) #log_hard_link = '.'.join([fname, ext]) log_name1 = '.'.join([fname, ext, fmt]) log_name2 = '.'.join([fname, ext]) log_name3 = '.'.join([fname, fmt, ext]) source_path1 = os.path.join(log_path, log_name1) source_path2 = os.path.join(log_path, log_name2) source_path3 = os.path.join(log_path, log_name3) target_path = os.path.join(log_path, log_hard_link) try: flag1 = False flag2 = False flag3 = False sz_arr = [0,0,0] if os.path.exists(source_path1): sz_arr[0] = os.path.getsize(source_path1) flag1 = True if os.path.exists(source_path2): sz_arr[1] = os.path.getsize(source_path2) flag2 = True if os.path.exists(source_path3): sz_arr[2] = os.path.getsize(source_path3) flag3 = True sz_max = sz_arr[0] sz_i = 0 for i in range(1,len(sz_arr)): if sz_arr[i] &gt; sz_max: sz_max = sz_arr[i] sz_i = i if sz_i == 0: flag1 = True flag2 = False flag3 = False elif sz_i == 1: flag1 = False flag2 = True flag3 = False elif sz_i == 2: flag1 = False flag2 = False flag3 = True #print('sp1_sz: &#123;&#125; sp2_sz: &#123;&#125;'.format(sp1_sz, sp2_sz)) #print('flag1: &#123;&#125; flag2: &#123;&#125;'.format(flag1, flag2)) #print('sp1: &#123;&#125; sp2: &#123;&#125;'.format(source_path1, source_path2)) #print('flag1: &#123;&#125; flag2: &#123;&#125; flag3: &#123;&#125;'.format(flag1,flag2,flag3)) if flag2 and os.path.exists(source_path2): if os.path.exists(target_path): f_stat = os.stat(target_path) if time.time() - f_stat.st_mtime &gt;= 5: if os.path.exists(target_path): os.unlink(target_path) os.link(source_path2, target_path) if not os.path.exists(target_path): os.link(source_path2, target_path) elif flag1 and os.path.exists(source_path1): if os.path.exists(target_path): f_stat = os.stat(target_path) if time.time() - f_stat.st_mtime &gt;= 5: if os.path.exists(target_path): os.unlink(target_path) os.link(source_path1, target_path) if not os.path.exists(target_path): os.link(source_path1, target_path) elif flag3 and os.path.exists(source_path3): if os.path.exists(target_path): f_stat = os.stat(target_path) if time.time() - f_stat.st_mtime &gt;= 5: if os.path.exists(target_path): os.unlink(target_path) os.link(source_path3, target_path) if not os.path.exists(target_path): os.link(source_path3, target_path) except: pass return target_pathdef printErrorLog(e, log=None): show = print if log: show = log show("Error Info: " + str(e)) show("Error File: " + str(e.__traceback__.tb_frame.f_globals["__file__"])) show("Error Row: " + str(e.__traceback__.tb_lineno)) show(e.args) show('Error Traceback:\n%s' % traceback.format_exc()) 多线程或者多进程工具 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567# -*- coding: utf-8 -*-import osimport sysimport timeimport randomfrom queue import Queue, LifoQueuefrom threading import Event, Threadfrom multiprocessing.managers import BaseManager, SyncManagerfrom multiprocessing.pool import ThreadPoolimport multiprocessing as mpimport multiprocessing.dummy as mp_dummyimport tracebackimport loggingfrom concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor# 一般如果是计算型任务，线程池的大小设置为cpu_num+1个，如果是IO型任务，设置为2*cpu_num+1个线程class MyManager(BaseManager): passMyManager.register('Event', Event)MyManager.register('Queue', LifoQueue)def printErrorLog(e, log=None): show = print if log: show = log show("Error Info: " + str(e)) show("Error File: " + str(e.__traceback__.tb_frame.f_globals["__file__"])) show("Error Row: " + str(e.__traceback__.tb_lineno)) show(e.args) show('Error Traceback:\n%s' % traceback.format_exc())class LogPrint: def __init__(self): pass def info(self, msg): print(msg) def error(self, msg): print(msg) def debug(self, msg): print(msg)def init_process(): if 'win32' == sys.platform: print('...freeze_support...') mp.freeze_support()# 多进程或者多线程主程序class MultiProcessTask: def __init__(self, pool_count=os.cpu_count(), log=None, app_queue_res_count=1, \ lifo_flag=False, thread_flag=True, result_flag=False, app_name='MultiProcessTask', \ app_func=None, show_log_flag=True, app_queue_req_max_size=0, \ app_queue_res_max_size=0, app_exec_timeout=None, new_impl=False, \ result_max_cache_size=None): # 定义日志 self.log : logging = log if log == None: self.log = LogPrint() if pool_count == None: pool_count = os.cpu_count() self.show_log_flag : bool = show_log_flag # 定义线程数 self.pool_count = pool_count # 定义应用名字 self.app_name = app_name app_manager : SyncManager = None if lifo_flag: manager = MyManager() manager.start() app_manager = manager #self.app_manager = Manager1() pass elif thread_flag: # 定义多线程管理 app_manager = mp_dummy.Manager() else: # 定义多进程管理 app_manager = mp.Manager() # 定义事件 用于通知关闭程序 self.app_event : Event = app_manager.Event() # 定义请求队列 self.app_queue_req : Queue = app_manager.Queue(app_queue_req_max_size) # 定义响应队列 self.app_queue_res : Queue = None if result_flag: self.app_queue_res = app_manager.Queue(app_queue_res_max_size) # 定义进程池 self.pool : ThreadPool if thread_flag: self.pool = mp_dummy.Pool(self.pool_count) else: self.pool = mp.Pool(self.pool_count) # 结果存取次数 self.app_queue_res_count = app_queue_res_count # 定义程序执行最大时长 self.app_exec_timeout = app_exec_timeout # 新方法实现 self.new_impl = new_impl # 默认执行方法 self.new_func = None # 定义执行方法 if app_func: self.add_func(app_func) else: if not self.new_impl: raise Exception('please init app_func!') else: self.add_func(None) # 结果缓存 self.result_cache_dct = &#123;&#125; # 结果ID列表 self.result_cache_id_list = [] # 结果最大缓存数量 # 最大缓存数量 = 线程数量 x 3 if result_max_cache_size: self.result_max_cache_size = result_max_cache_size else: self.result_max_cache_size = self.pool_count * 3 if thread_flag: self.log.info(f'&#123;self.app_name&#125; threads total: &#123;self.pool_count&#125; mpt init...') else: self.log.info(f'&#123;self.app_name&#125; process total: &#123;self.pool_count&#125; mpt init...') # 定义异步错误信息 def err_callback(self, err: Exception, app_name=''): self.log.error(f'&#123;app_name&#125; app_func error &gt; &#123;err&#125;') printErrorLog(err, self.log.error) return True # 初始化默认执行方法 def init_new_func(self, app_func): self.new_func = app_func # 实现方法传递 def handle_new_func(self, params=&#123;&#125;, app_func=None): key = '_app_func' if key not in params: if app_func: params['_app_func'] = app_func elif self.new_func: params['_app_func'] = self.new_func t = int(time.time() * 10000000) rand = random.randint(1,99999999) uk_id = f'&#123;t&#125;&#123;rand&#125;' params['_app_req_id'] = uk_id return uk_id # 定义执行方法 def add_func(self, app_func): mptf = MultiProcessTaskFunc( log = self.log, app_name = self.app_name, app_event = self.app_event, app_queue_req = self.app_queue_req, app_queue_res = self.app_queue_res, app_queue_res_count = self.app_queue_res_count, app_func = app_func, show_log_flag = self.show_log_flag, app_exec_timeout=self.app_exec_timeout ) for _ in range(self.pool_count): if self.new_impl: self.pool.apply_async(func=mptf.init_method,error_callback=self.err_callback) else: self.pool.apply_async(func=mptf.init_method_old,error_callback=self.err_callback) # 等待执行完成,并且释放资源 def close(self, forceFlag=False): if not forceFlag: if not self.app_queue_req.empty(): self.app_queue_req.join() if not self.app_event.is_set(): self.app_event.set() for _ in range(self.pool_count): self.app_queue_req.put(None) self.pool.close() if not forceFlag: self.pool.join() # 发送请求并拿到数据 def sendReqAndReceiveRes(self, params=&#123;&#125;, timeout=180, app_func=None): if self.new_impl: self.handle_new_func(params,app_func) self.app_queue_req.put(params) if self.app_queue_res: try: res = self.app_queue_res.get(timeout=timeout) self.app_queue_res.task_done() if res: return res except: pass return &#123;&#125; else: return True def send_req_and_receive_res(self, params=&#123;&#125;, timeout=180): self.sendReqAndReceiveRes(params,timeout) # 等待请求执行完毕 def waitReqComplete(self): self.app_queue_req.join() def wait_req_complete(self): self.waitReqComplete() # 缓存返回结果 def cache_result_done_func(self, result:dict): if self.result_max_cache_size &lt; len(self.result_cache_id_list): for _ in range(len(self.result_cache_id_list)-self.result_max_cache_size): result_cache_key = self.result_cache_id_list.pop() try: del self.result_cache_dct[result_cache_key] except Exception: pass try: for k, v in result.items(): self.result_cache_id_list.append(k) self.result_cache_dct[k] = v #self.log.info(f'result_cache_id_list ==&gt; &#123;self.result_cache_id_list&#125;') #self.log.info(f'result_cache_dct ==&gt; &#123;self.result_cache_dct&#125;') except Exception: pass # 获取返回值实现方法 def get_cache_result_func(self, key): res = None key_ = None if key in self.result_cache_dct: res = self.result_cache_dct[key] del self.result_cache_dct[key] key_ = key try: self.result_cache_id_list.remove(key) except Exception: pass return res, key_ # 获取返回值 def get_cache_result(self, key, wait_req_done=False): while True: res = self.get_cache_result_func(key) if res[1] is not None: return res[0] if wait_req_done: self.app_queue_req.join() while not self.app_queue_res.empty(): try: data = self.app_queue_res.get_nowait() self.app_queue_res.task_done() self.cache_result_done_func(data) except Exception: pass time.sleep(0.1) def getCacheResult(self, key, waitReqDone=False): return self.get_cache_result(key,waitReqDone) # 批量获取返回值 def batch_get_cache_result(self, keys:list, wait_req_done=False): result_arr = [] for key in keys: res = self.get_cache_result(key,wait_req_done) result_arr.append(res) return result_arr def batchGetCacheResult(self, keys:list, waitReqDone=False): return self.batch_get_cache_result(keys,waitReqDone) # 获取返回值无key def get_cache_result_no_key(self, wait_req_done=False): while True: if wait_req_done: self.app_queue_req.join() result_arr = [] while not self.app_queue_res.empty(): try: data:dict = self.app_queue_res.get_nowait() self.app_queue_res.task_done() for k, v in data.items(): if wait_req_done: result_arr.append(v) else: return v except Exception: pass if wait_req_done: return result_arr time.sleep(0.1) def getCacheResultNoKey(self, waitReqDone=False): return self.get_cache_result_no_key(waitReqDone) # 发送请求 def sendReq(self, params=&#123;&#125;, app_func=None): app_req_id = None if self.new_impl: app_req_id = self.handle_new_func(params,app_func) self.app_queue_req.put(params) return app_req_id def send_req(self, params=&#123;&#125;, app_func=None): return self.sendReq(params,app_func) # 批量发送请求 def sendReqArr(self, paramsArr=[]): app_req_id_arr = [] for params in paramsArr: app_req_id = self.sendReq(params) app_req_id_arr.append(app_req_id) return app_req_id_arr def send_req_arr(self, paramsArr=[]): return self.sendReqArr(paramsArr) # 清空请求 def clearReq(self): while not self.app_queue_req.empty(): self.app_queue_req.get() self.app_queue_req.task_done() return True def clear_req(self): return self.clearReq() # 清空请求与响应 def clearReqAndRes(self): f1 = self.clearReq() f2 = self.clearRes() return f1 and f2 def clear_req_and_res(self): return self.clearReqAndRes() # 返回请求队列是否为空 def reqQueueIsEmpty(self): return self.app_queue_req.empty() def req_queue_is_empty(self): return self.reqQueueIsEmpty() # 返回响应队列是否为空 def resQueueIsEmpty(self): return self.app_queue_res.empty() def res_queue_is_empty(self): return self.resQueueIsEmpty() # 接收请求 def receiveRes(self, allFlag=False): if allFlag: self.waitReqComplete() data_arr = [] if self.app_queue_res: while not self.app_queue_res.empty(): data = self.app_queue_res.get() self.app_queue_res.task_done() data_arr.append(data) return data_arr else: data = &#123;&#125; if self.app_queue_res: data = self.app_queue_res.get() self.app_queue_res.task_done() return data def receive_res(self, all_flag=False): return self.receiveRes(all_flag) # 清空结果 def clearRes(self): while not self.app_queue_res.empty(): self.app_queue_res.get() self.app_queue_res.task_done() return True def clear_res(self): return self.clearRes() def sendReqNoResult(self, params=&#123;&#125;): if self.app_queue_req.qsize() &lt; self.pool_count: self.app_queue_req.put(params) else: self.app_queue_req.join() return True def send_req_no_result(self, params=&#123;&#125;): return self.sendReqNoResult(params) def sendReqGetResult(self, params=&#123;&#125;, results : list = [], timeout=None): if not self.app_queue_res: return False if self.app_queue_req.qsize() &gt;= self.pool_count: for i in range(self.pool_count): if self.app_queue_req.empty() and self.app_queue_res.empty(): break res = self.app_queue_res.get(timeout=timeout) self.app_queue_res.task_done() results.append(res) self.app_queue_req.put(params) def send_req_get_result(self, params=&#123;&#125;, results : list = [], timeout=None): return self.sendReqGetResult(params, results, timeout) def __enter__(self): return self def __exit__(self,exc_type,exc_val,exc_tb): try: if not exc_type is None: self.log.info('exception_type: &#123;&#125;'.format(exc_type)) self.log.info('exception_val: &#123;&#125;'.format(exc_val)) self.log.info('exception_tb: &#123;&#125;'.format(exc_tb)) self.close(forceFlag=True) raise exc_val else: pass except Exception as e: printErrorLog(e,self.log) raise e finally: self.close() return Trueclass MultiProcessTaskFunc: def __init__(self, log=None, app_name=None, app_event=None, app_queue_req=None, app_queue_res=None, \ app_queue_res_count=None, app_func=None, show_log_flag=True, app_exec_timeout=None): # 定义日志 self.log : logging = log # 停止打印日志 self.show_log_flag : bool = show_log_flag # 定义应用名字 self.app_name : str = app_name # 定义事件 用于通知关闭程序 self.app_event : Event = app_event # 定义请求队列 self.app_queue_req : Queue = app_queue_req # 定义响应队列 self.app_queue_res : Queue = app_queue_res # 结果存取次数 self.app_queue_res_count : int = app_queue_res_count self.app_func = app_func # 超时时间 默认永久 self.app_exec_timeout = app_exec_timeout # 定义异步错误信息 def err_callback(self, err: Exception, app_name=''): self.log.error(f'&#123;app_name&#125; app_func error &gt; &#123;err&#125;') printErrorLog(err, self.log.error) # 定义执行方法并且设定超时时长 def handle_exec_app_func_old(self, app_req, task_index): if self.app_exec_timeout: try: pool: ThreadPool = mp_dummy.Pool(1) future = pool.apply_async(self.app_func,[app_req]) return future.get(self.app_exec_timeout) except Exception as e: self.err_callback(e,f'&#123;self.app_name&#125;_&#123;task_index&#125;') finally: pool.close() else: try: return self.app_func(app_req) except Exception as e: self.err_callback(e,f'&#123;self.app_name&#125;_&#123;task_index&#125;') return None # 执行方法实现 def init_method_old(self): task_index = f'&#123;int(time.time())&#125;&#123;random.randint(100,999)&#125;' if self.show_log_flag: self.log.info(f'&#123;self.app_name&#125;_&#123;task_index&#125; start...') while not self.app_event.is_set(): req = self.app_queue_req.get() if not req: self.app_queue_req.task_done() continue res = self.handle_exec_app_func_old(req, task_index) self.app_queue_req.task_done() if self.app_queue_res: for _ in range(self.app_queue_res_count): try: self.app_queue_res.put(res) except: pass if self.show_log_flag: self.log.info(f'&#123;self.app_name&#125;_&#123;task_index&#125; end...') # 定义执行方法并且设定超时时长 def handle_exec_app_func(self, app_req, task_index): app_func = None if '_app_func' in app_req: app_func = app_req['_app_func'] del app_req['_app_func'] else: app_func = self.app_func app_req_id = None if '_app_req_id' in app_req: app_req_id = app_req['_app_req_id'] del app_req['_app_req_id'] if self.app_exec_timeout: try: pool: ThreadPool = mp_dummy.Pool(1) future = pool.apply_async(app_func,kwds=app_req) res = future.get(self.app_exec_timeout) if app_req_id: return &#123;app_req_id:res&#125; return res except Exception as e: self.err_callback(e,f'&#123;self.app_name&#125;_&#123;task_index&#125;') finally: pool.close() else: try: res = app_func(**app_req) if app_req_id: return &#123;app_req_id:res&#125; return res except Exception as e: self.err_callback(e,f'&#123;self.app_name&#125;_&#123;task_index&#125;') return None # 执行方法实现 def init_method(self): task_index = f'&#123;int(time.time())&#125;&#123;random.randint(100,999)&#125;' if self.show_log_flag: self.log.info(f'&#123;self.app_name&#125;_&#123;task_index&#125; start...') while not self.app_event.is_set(): req = self.app_queue_req.get() if not req: self.app_queue_req.task_done() continue res = self.handle_exec_app_func(req, task_index) self.app_queue_req.task_done() if self.app_queue_res: for _ in range(self.app_queue_res_count): try: self.app_queue_res.put(res) except: pass if self.show_log_flag: self.log.info(f'&#123;self.app_name&#125;_&#123;task_index&#125; end...')]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python操作mysql]]></title>
    <url>%2F2023%2F01%2F04%2Fpython%E6%93%8D%E4%BD%9Cmysql%2F</url>
    <content type="text"><![CDATA[Python操作Mysql python3.8.5测试通过 mysql数据封装成字典类型12# 核心代码self.cursor = self.conn.cursor(pymysql.cursors.DictCursor) 封装成常用的工具123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305# -*- coding: utf-8 -*-import pymysqlclass DbMysqlTool(object): def __init__(self,params=&#123;&#125;): if 'host' in params and params['host']: self.host = params['host'] else: self.host = '127.0.0.1' if 'port' in params and params['port'] != '': self.port = params['port'] else: self.port = 3306 if 'database' in params and params['database']: self.database = params['database'] else: self.database = 'img_db' if 'username' in params and params['username']: self.username = params['username'] else: self.username = 'root' if 'password' in params and params['password']: self.password = params['password'] else: self.password = 'root' if 'charset' in params and params['charset']: self.charset = params['charset'] else: self.charset = 'utf8mb4' def db_conn(self, dictFlag=False): self.conn = pymysql.connect( host=self.host, port=self.port, database=self.database, user=self.username, password=self.password, charset=self.charset ) if dictFlag: self.cursor = self.conn.cursor(pymysql.cursors.DictCursor) else: self.cursor = self.conn.cursor() def db_close(self): try: if self.cursor: self.cursor.close() except: pass try: if self.conn: self.conn.close() except: pass def escape_string(self,val): return pymysql.converters.escape_string(val) def check_params_val(self,params,key): return params and key in params and params[key] def get_params_val(self,params,key): if self.check_params_val(params,key): return params[key] else: return '' def db_parser_params(self,params): sql_table = self.get_params_val(params,'table') sql_params = self.get_params_val(params,'params') sql_where = self.get_params_val(params,'where') if sql_where: sql_where = 'WHERE ' + sql_where sql = '' if self.get_params_val(params,'sql'): sql = self.get_params_val(params,'sql') elif self.get_params_val(params,'insert_flag'): values = '' total = len(sql_params.split(',')) values = ', '.join(['%s' for _ in range(total)]) sql = 'INSERT INTO &#123;table&#125; (&#123;params&#125;) VALUES (&#123;values&#125;);'\.format(table=sql_table,params=sql_params,values=values) elif self.get_params_val(params,'update_flag'): if sql_params: params_arr = sql_params.split(',') params_tmp = [ f + ' = %s' for f in params_arr] params_val = ', '.join(params_tmp) sql = 'UPDATE &#123;table&#125; SET &#123;params&#125; &#123;where&#125;;'.format(table=sql_table,\params=params_val,where=sql_where) elif self.get_params_val(params,'delete_flag'): sql = 'DELETE FROM &#123;table&#125; &#123;where&#125;;'.format(table=sql_table,where=sql_where) elif self.get_params_val(params,'select_flag'): if not sql_params: sql_params = '*' group_by = self.get_params_val(params,'group_by') if group_by: group_by = ' GROUP BY &#123;0&#125;'.format(group_by) having = self.get_params_val(params,'having') if having: having = ' HAVING &#123;0&#125;'.format(having) asc = self.get_params_val(params,'order_by_asc') if asc: asc_arr = asc.split(',') asc = [f + ' ASC' for f in asc_arr] asc = ','.join(asc) desc = self.get_params_val(params,'order_by_desc') if desc: desc_arr = desc.split(',') desc = [f + ' DESC' for f in desc_arr] desc = ','.join(desc) if asc and desc: order_by = 'ORDER BY &#123;0&#125;, &#123;1&#125;'.format(asc,desc) elif asc or desc: order_by = 'ORDER BY &#123;0&#125; &#123;1&#125;'.format(asc,desc) else: order_by = '' limit = self.get_params_val(params,'limit') if limit: limit = 'LIMIT &#123;0&#125;'.format(limit) last = self.get_params_val(params,'last') if last: last = '&#123;0&#125;'.format(last) sql = 'SELECT &#123;params&#125; FROM &#123;table&#125; &#123;where&#125; &#123;group_by&#125; &#123;having&#125; &#123;order_by&#125; &#123;limit&#125; &#123;last&#125;'\.format(params=sql_params,table=sql_table,where=sql_where,group_by=group_by,having=having,\order_by=order_by,limit=limit,last=last) return sql def update_one(self,sql,values=''): try: self.db_conn() if values: self.cursor.execute(sql,values) else: self.cursor.execute(sql) self.conn.commit() return True except Exception as e: print(e) self.conn.rollback() finally: self.db_close() return False def update_batch(self,sql,values=''): try: self.db_conn() if values: self.cursor.executemany(sql,values) else: self.cursor.executemany(sql) self.conn.commit() return True except Exception as e: print(e) self.conn.rollback() finally: self.db_close() return False def insert_one(self,params): try: params['insert_flag'] = True sql = self.db_parser_params(params) values = self.get_params_val(params,'values') return self.update_one(sql,values) except Exception as e: print(e) return False def insert_batch(self,params): try: params['insert_flag'] = True sql = self.db_parser_params(params) values = self.get_params_val(params,'values') return self.update_batch(sql,values) except Exception as e: print(e) return False def update(self,params): try: params['update_flag'] = True sql = self.db_parser_params(params) values = self.get_params_val(params,'values') return self.update_one(sql,values) except Exception as e: print(e) return False def delete(self,params): try: params['delete_flag'] = True sql = self.db_parser_params(params) values = self.get_params_val(params,'values') return self.update_one(sql,values) except Exception as e: print(e) return False def select_one(self,params): try: params['select_flag'] = True values = self.get_params_val(params,'values') sql = self.db_parser_params(params) self.db_conn(dictFlag=True) if values: self.cursor.execute(sql,values) else: self.cursor.execute(sql) rows = self.cursor.fetchone() return rows except Exception as e: print(e) finally: self.db_close() return '' def select_batch(self,params): try: params['select_flag'] = True values = self.get_params_val(params,'values') sql = self.db_parser_params(params) self.db_conn(dictFlag=True) if values: self.cursor.execute(sql,values) else: self.cursor.execute(sql) rows = self.cursor.fetchall() return rows except Exception as e: print(e) finally: self.db_close() return '' def count(self,params): try: params['select_flag'] = True values = self.get_params_val(params,'values') if not self.check_params_val(params,'params'): params['params'] = 'COUNT(1)' sql = self.db_parser_params(params) self.db_conn() if values: self.cursor.execute(sql,values) else: self.cursor.execute(sql) return int(self.cursor.fetchone()[0]) except Exception as e: print(e) finally: self.db_close() return 0if __name__ == '__main__': dt = DbMysqlTool() # 插入 insert_models = &#123; 'name': 'sakura', 'gender': 'female', 'age': 18 &#125; dt.insert_one(&#123; 'table': 'test_table', 'params': ','.join(insert_models.keys()), 'values': list(insert_models.values()) &#125;) # 更新 update_models = &#123; 'name': 'sakura', 'gender': 'female', 'age': 18 &#125; values = list(update_models.values()) values.append(1) dt.update(&#123; 'table': 'test_table', 'params': ','.join(update_models.keys()), 'where': 'id = %s', 'values': values &#125;) # 删除 dt.delete(&#123; 'table': 'test_table', 'where': 'id = %s', 'values': (1,) &#125;) # 查询 dt.select_one(&#123; 'table': 'test_table', 'where': 'id = %s', 'values': (1,) &#125;) dt.select_batch(&#123; 'table': 'test_table', 'where': 'id &lt;= %s', 'values': (10,) &#125;) dt.count(&#123; 'table': 'test_table' &#125;) pass]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python操作sqlite]]></title>
    <url>%2F2023%2F01%2F03%2Fpython%E6%93%8D%E4%BD%9Csqlite%2F</url>
    <content type="text"><![CDATA[Python操作Sqlite python3.8.5测试通过 sqlite数据封装为字典类型12345678# 核心代码self.conn.row_factory = self.dict_factorydef dict_factory(self, cursor, row): d = &#123;&#125; for idx, col in enumerate(cursor.description): d[col[0]] = row[idx] return d 封装成常用的工具123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278# -*- coding: utf-8 -*-import sqlite3DATABASE_NAME = 'records.db'class DbSqliteTool(object): def __init__(self): self.database = DATABASE_NAME def db_conn(self,dictFlag=False): self.conn = sqlite3.connect(self.database) if dictFlag: self.conn.row_factory = self.dict_factory self.cursor = self.conn.cursor() def db_close(self): try: if self.cursor: self.cursor.close() except: pass try: if self.conn: self.conn.close() except: pass def dict_factory(self, cursor, row): d = &#123;&#125; for idx, col in enumerate(cursor.description): d[col[0]] = row[idx] return d def check_params_val(self,params,key): return params and key in params and params[key] def get_params_val(self,params,key): if self.check_params_val(params,key): return params[key] else: return '' def db_parser_params(self,params): sql_table = self.get_params_val(params,'table') sql_params = self.get_params_val(params,'params') sql_where = self.get_params_val(params,'where') if sql_where: sql_where = 'WHERE ' + sql_where sql = '' if self.get_params_val(params,'sql'): sql = self.get_params_val(params,'sql') elif self.get_params_val(params,'insert_flag'): values = '' total = len(sql_params.split(',')) values = ', '.join(['?' for _ in range(total)]) sql = 'INSERT INTO &#123;table&#125; (&#123;params&#125;) VALUES (&#123;values&#125;);'\.format(table=sql_table,params=sql_params,values=values) elif self.get_params_val(params,'update_flag'): if sql_params: params_arr = sql_params.split(',') params_tmp = [ f + ' = ?' for f in params_arr] params_val = ', '.join(params_tmp) sql = 'UPDATE &#123;table&#125; SET &#123;params&#125; &#123;where&#125;;'.format(table=sql_table,\params=params_val,where=sql_where) elif self.get_params_val(params,'delete_flag'): sql = 'DELETE FROM &#123;table&#125; &#123;where&#125;;'.format(table=sql_table,where=sql_where) elif self.get_params_val(params,'select_flag'): if not sql_params: sql_params = '*' group_by = self.get_params_val(params,'group_by') if group_by: group_by = ' GROUP BY &#123;0&#125;'.format(group_by) having = self.get_params_val(params,'having') if having: having = ' HAVING &#123;0&#125;'.format(having) asc = self.get_params_val(params,'order_by_asc') if asc: asc_arr = asc.split(',') asc = [f + ' ASC' for f in asc_arr] asc = ','.join(asc) desc = self.get_params_val(params,'order_by_desc') if desc: desc_arr = desc.split(',') desc = [f + ' DESC' for f in desc_arr] desc = ','.join(desc) if asc and desc: order_by = 'ORDER BY &#123;0&#125;, &#123;1&#125;'.format(asc,desc) elif asc or desc: order_by = 'ORDER BY &#123;0&#125; &#123;1&#125;'.format(asc,desc) else: order_by = '' limit = self.get_params_val(params,'limit') if limit: limit = 'LIMIT &#123;0&#125;'.format(limit) last = self.get_params_val(params,'last') if last: last = '&#123;0&#125;'.format(last) sql = 'SELECT &#123;params&#125; FROM &#123;table&#125; &#123;where&#125; &#123;group_by&#125; &#123;having&#125; &#123;order_by&#125; &#123;limit&#125; &#123;last&#125;'\.format(params=sql_params,table=sql_table,where=sql_where,group_by=group_by,having=having,\order_by=order_by,limit=limit,last=last) return sql def update_one(self,sql,values=''): try: self.db_conn() if values: self.cursor.execute(sql,values) else: self.cursor.execute(sql) self.conn.commit() return True except Exception as e: print(e) self.conn.rollback() finally: self.db_close() return False def update_batch(self,sql,values=''): try: self.db_conn() if values: self.cursor.executemany(sql,values) else: self.cursor.executemany(sql) self.conn.commit() return True except Exception as e: print(e) self.conn.rollback() finally: self.db_close() return False def insert_one(self,params): try: params['insert_flag'] = True sql = self.db_parser_params(params) values = self.get_params_val(params,'values') return self.update_one(sql,values) except Exception as e: print(e) return False def insert_batch(self,params): try: params['insert_flag'] = True sql = self.db_parser_params(params) values = self.get_params_val(params,'values') return self.update_batch(sql,values) except Exception as e: print(e) return False def update(self,params): try: params['update_flag'] = True sql = self.db_parser_params(params) values = self.get_params_val(params,'values') return self.update_one(sql,values) except Exception as e: print(e) return False def delete(self,params): try: params['delete_flag'] = True sql = self.db_parser_params(params) values = self.get_params_val(params,'values') return self.update_one(sql,values) except Exception as e: print(e) return False def select_one(self,params): try: params['select_flag'] = True sql = self.db_parser_params(params) values = self.get_params_val(params,'values') self.db_conn(dictFlag=True) if values: self.cursor.execute(sql,values) else: self.cursor.execute(sql) rows = self.cursor.fetchone() return rows except Exception as e: print(e) finally: self.db_close() return '' def select_batch(self,params): try: params['select_flag'] = True values = self.get_params_val(params,'values') sql = self.db_parser_params(params) self.db_conn(dictFlag=True) if values: self.cursor.execute(sql,values) else: self.cursor.execute(sql) rows = self.cursor.fetchall() return rows except Exception as e: print(e) finally: self.db_close() return '' def count(self,params): try: params['select_flag'] = True values = self.get_params_val(params,'values') if not self.check_params_val(params,'params'): params['params'] = 'COUNT(1)' sql = self.db_parser_params(params) self.db_conn() if values: self.cursor.execute(sql,values) else: self.cursor.execute(sql) return int(self.cursor.fetchone()[0]) except Exception as e: print(e) finally: self.db_close() return 0if __name__ == '__main__': dt = DbSqliteTool() # 插入 insert_models = &#123; 'name': 'sakura', 'gender': 'female', 'age': 18 &#125; dt.insert_one(&#123; 'table': 'test_table', 'params': ','.join(insert_models.keys()), 'values': list(insert_models.values()) &#125;) # 更新 update_models = &#123; 'name': 'sakura', 'gender': 'female', 'age': 18 &#125; values = list(update_models.values()) values.append(1) dt.update(&#123; 'table': 'test_table', 'params': ','.join(update_models.keys()), 'where': 'id = ?', 'values': values &#125;) # 删除 dt.delete(&#123; 'table': 'test_table', 'where': 'id = ?', 'values': (1,) &#125;) # 查询 dt.select_one(&#123; 'table': 'test_table', 'where': 'id = ?', 'values': (1,) &#125;) dt.select_batch(&#123; 'table': 'test_table', 'where': 'id &lt;= ?', 'values': (10,) &#125;) dt.count(&#123; 'table': 'test_table' &#125;) pass]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[openssl自签证书]]></title>
    <url>%2F2022%2F01%2F14%2Fopenssl%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[OpenSSL自签证书 该步骤在win10-msys2测试通过 建立私钥(最少要输入4位数的密码) 1openssl genrsa -des3 -out server.key 2048 通过server.key生成server.csr 1openssl req -new -key server.key -out server.csr 去掉私钥密码(可选) 1openssl rsa -in server.key -out server_no_passwd.key 生成无密码验证的证书 1openssl x509 -req -days 365 -in server.csr -signkey server_no_passwd.key -out server.crt]]></content>
      <categories>
        <category>OpenSSL</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[IDEA 建立mybatis-plus项目出现"Invalid bound statement (not found)"如何处理]]></title>
    <url>%2F2021%2F10%2F19%2FIDEA%E5%BB%BA%E7%AB%8Bmybatis-plus%E9%81%87%E5%88%B0%E6%89%BE%E4%B8%8D%E5%88%B0%E8%AF%AD%E5%8F%A5%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[首先这个问题是怎么出现的 org.apache.ibatis.binding.BindingException: Invalid bound statement (not found): xxxx 语法错误 (xml的标签与接口方法不对应) 参数类型错误 (xml的传参参数与返回参数错误) 编译错误 (xml并没有编译进去) 配置错误 (配置参数漏了或者写错了 xml资源路径错误 (这是重点,如果不细心的话,很难找到问题所在) 重点说明资源路径为什么会错 某一次照常建立关于mybatis-plus的项目,然后运行自定SQL的时候突然出现这篇文章提到的问题。花了好几天都是这个错误,尝试改配置、重新建立项目同样是这种问题。唯独这个xml写的自定义sql无法执行,其他方法都是能够正常执行的。 后面发现IDEAresources新建文件夹的时候使用mapper.system与mapper/system他们展示的结构都是一样的,然而这两者的意义却不一样。mapper.system相当于这个文件夹就是这个名字,而mapper/system是建立二级目录,而那个配置文件没法识别mapper.system，所以问题这个是微不足道的细节导致的。 总结这个问题困扰我好几天,后面找到问题所在,才发现是这个细节问题。后续开发一定要细心,否则会吃大亏。]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[运用python获取bing每日壁纸]]></title>
    <url>%2F2020%2F01%2F10%2F%E8%BF%90%E7%94%A8python%E8%8E%B7%E5%8F%96bing%E6%AF%8F%E6%97%A5%E5%A3%81%E7%BA%B8%2F</url>
    <content type="text"><![CDATA[运用python获取bing每日壁纸 测试环境 –&gt; windows10,android(termux) : python3.5以上 首先需要安装python,下最新的就行官方下载 确保pip也安装,接着安装相关依赖 feedparser beautifulsoup4 requests 12安装以上依赖pip install xxxx 脚本作用执行脚本,会生成一个当前日期的文件夹,里面有当天的图片与json文件 源码如下 使用rsshub.app 每日壁纸 https://docs.rsshub.app/picture.html#bing-bi-zhi 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# -*- coding: utf-8 -*-import feedparserfrom bs4 import BeautifulSoupimport jsonimport timeimport osimport requests# 获取图片信息def getImg(info): html = BeautifulSoup(info, 'html.parser') img = html.img.attrs['src'] index = img.index('&amp;') img = img[:index] return img# 获取指定信息def getInfo(url): # 获取每日bing壁纸 d = feedparser.parse(url) feed = d.feed data = dict(title=feed.title,url=feed.link,desc=feed.description) items = [] values = d.entries for value in values: item = dict() item['desc'] = value.title item['link'] = getImg(value.summary) items.append(item) data['values'] = items return datadef main(): print('开始获取每日bing图片...') url = 'https://rsshub.app/bing' data = getInfo(url) date = time.strftime('%Y-%m-%d') ext = '.json' file = date + ext # 判断文件是否存在 if os.path.exists(date): print('数据已存在') return # 首先创建文件夹 os.mkdir(date) # 改变工作目录 os.chdir(date) # 保存json文件 with open(file, 'w+', encoding='utf-8') as f: json.dump(data, f, ensure_ascii=False, indent=4) # 保存图片 n = 0 for item in data['values']: n = n + 1 link = item['link'] ext = os.path.splitext(link)[1] img = requests.get(link) file = str(n)+ext with open(file, 'wb+') as f: f.write(img.content) print('结束获取每日bing图片')if __name__ == '__main__': main()]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux备份]]></title>
    <url>%2F2019%2F04%2F26%2FLinux%E5%A4%87%E4%BB%BD%2F</url>
    <content type="text"><![CDATA[Linux 系统备份 测试环境 –&gt; debian 9.x 尝试完整备份 dd tar rsync 此次使用rsync 支持远程备份还原时，注意引导修复可能需要linux livecd修复 同步工具1rsync -aAXv --exclude=&#123;"/dev/*","/proc/*","/sys/*","/tmp/*","/run/*","/mnt/*","/media/*","/lost+found"&#125; / /path/to/backup/folder 说明 -a, ––archive 归档模式，表示以递归方式传输文件，并保持所有文件属性 -v, ––verbose 详细输出模式 -P 显示同步过程，比如速率，比-v更加详细 –exclude=PATTERN 指定排除不需要传输的文件 -X, –xattrs 此选项使rsync更新目标扩展属性与源代码相同 -aAX 通过使用-aAX选项集，文件以归档模式传输，确保保留符号链接，设备，权限，所有权，修改时间，ACL和扩展属性，假设目标文件系统支持该功能 1234本地备份rsync -aAXv -aAXv --exclude=&#123;"/dev/*","/proc/*","/sys/*","/tmp/*","/run/*","/mnt/*","/media/*","/lost+found"&#125; / /mnt/system远程备份rsync -aAXv --exclude=&#123;"/dev/*","/proc/*","/sys/*","/tmp/*","/run/*","/mnt/*","/media/*","/lost+found"&#125; 用户名@服务器地址:/ /mnt/system 文件解压缩1234压缩tar -jcpvf 压缩文件名.tar.bz2 需要压缩的文件或目录解压tar -xvf 压缩文件名.tar.(bz2,gz) 当前位置 -C 指定目录 说明 -j 使用bz2 -c 压缩档案 -x 解压档案 -p 保留原有的权限 -v 显示进度 -f 文件名 -C 指定目录位置 1234压缩文件可以节省空间tar -jcpvf 保存的位置/文件名.tar.bz2 -C 需要压缩的目录位置 需要压缩哪些文件比如tar -jcpvf /mnt/debian.tar.bz2 -C /mnt/system . 远程连接1ssh 用户名@服务器地址 远程下载上传1scp 用户名@服务器地址:指定目录 下载目录 (上传在左边,下载在右边) 引导修复 通用 大前提 进入Linux Live CD分好区并且格式化，然后挂载需要还原的分区 首先需要挂载相关目录 123mount --bind /dev /mnt/devmount --bind /proc /mnt/procmount --bind /sys /mnt/sys 进入该目录 1chroot /mnt /bin/bash 1blkid 查看分区uuid 将获取到的uuid(安装的系统分区)修改 /etc/fstab 传统引导 12grub-install /dev/sdagrub-mkconfig -o /boot/grub/grub.cfg uefi引导 首先需要挂载efi分区，以及修改/etc/fstab (blkid可以获取uuid) 12grub-install --target=x86_64-efi --efi-directory=esp目录 --bootloader-id=名字grub-mkconfig -o /boot/grub/grub.cfg]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu Server虚拟机安装]]></title>
    <url>%2F2018%2F12%2F21%2FUbuntu-Server%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[用虚拟机(VMware)安装Ubuntu Server去官网下载Ubuntu Server(这里是纯字符界面的系统) 打开VM软件，并新建一个虚拟机 启动虚拟机并安装系统按回车键(“Enter”)选择选择完后，会让你选择语言，我们选择English接着选择哪个地区，这里选择United States(美国)它又会弹出一个窗口，是否检测键盘布局，选择否，默认就行紧接着，选择键盘标准，选择English(US) 中国的键盘是遵循美式的等待该系统设置接着，我们设置该系统的hostname 根据自己所需而定对这个用户的完整称呼接着，设置自己的用户名然后，设置密码需要重新输入一遍如果密码太简单，它会弹出是否使用弱口令(密码) 选择是又会弹出是否加密主目录， 没必要 选择NO又会检查时区的设置，联网自动帮你矫正好，直接下一步就行了接着分区，这里我们默认系统分区就行，如果自己想要更明确的分区，就需要手动分区(请自己去百度)等待系统安装。。。又会弹出是否需要代理服务什么的，不需要 跳过就行了等待所需软件安装完毕。。。是否自动更新，这里我们选择 不自动更新(当然你可以选择自动更新)它又会让我们选择安装那些服务套件功能，只要Samaba 局域网共享与OpenSSH远程控制Linux，以及默认standard system utilities等待安装完成。。。然后引导分区结束安装又会弹出这样的提示，确认即可重启后，进入登录界面 登录Ubuntu登陆成功后，等待用户输入开始Linux之旅吧! 可选添加国内源 加入国内的源，默认是外国的因此下载默认软件速度很慢，就需要我们手动加入了。这里是国内目前常用的源阿里源 https://mirrors.aliyun.com/ubuntu/网易源 http://mirrors.163.com/ubuntu/清华源 https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ 输入sudo vim /etc/apt/sources.list (善于利用linux的tab自动补全) 输入密码修改 我们开始更新系统sudo apt-get update &amp;&amp; sudo apt-get upgrade 如果有让我们输入选项，选择是即可 Y 以后的选项都是如此 配置SamabaSamaba让Windows也能访问Linux的文件1sudo vim /etc/samba/smb.conf 例如123456789workgroup = WORKGROUP windows主机[fileshare] comment = 共享名 path = /home/heros 共享路径 browseable = yes 可以浏览 writeable = yes 可写 available = yes 可用 valid users = heros 允许访问用户 ready only = no 不只读 使用系统用户1sudo smbpasswd –a heros 它让你设置密码 完成后，然后重启samba服务1sudo service smbd restart windows的资源管理输入//ip地址就行了，提示输入用户名与密码就可以访问Linux的文件目录了 配置ftp安装ftp服务1sudo apt-get install vsftpd 按“y”确认安装 修改配置文件1sudo vim /etc/vsftpd.conf 将以下配置的#注释去掉 找#按”x”键可快速删除12write_enable=YES 可写utf8_filesystem=YES 以utf8编码传输 重启服务1sudo service vsftpd restart]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[vim的使用]]></title>
    <url>%2F2018%2F12%2F13%2Fvim%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[vim的基本使用 引用 菜鸟教程 基本上 vi/vim 共分为三种模式，分别是命令模式（Command mode），输入模式（Insert mode）和底线命令模式（Last line mode）。 命令模式：用户刚刚启动 vi/vim，便进入了命令模式。 此状态下敲击键盘动作会被Vim识别为命令，而非输入字符。比如我们此时按下i，并不会输入一个字符，i被当作了一个命令。 以下是常用的几个命令： i 切换到输入模式，以输入字符。x 删除当前光标所在处的字符。: 切换到底线命令模式，以在最底一行输入命令。若想要编辑文本：启动Vim，进入了命令模式，按下i，切换到输入模式。 命令模式只有一些最基本的命令，因此仍要依靠底线命令模式输入更多命令。 输入模式在命令模式下按下i就进入了输入模式。 在输入模式中，可以使用以下按键： 字符按键以及Shift组合，输入字符ENTER，回车键，换行BACK SPACE，退格键，删除光标前一个字符DEL，删除键，删除光标后一个字符方向键，在文本中移动光标HOME/END，移动光标到行首/行尾Page Up/Page Down，上/下翻页Insert，切换光标为输入/替换模式，光标将变成竖线/下划线ESC，退出输入模式，切换到命令模式底线命令模式在命令模式下按下:（英文冒号）就进入了底线命令模式。 底线命令模式可以输入单个或多个字符的命令，可用的命令非常多。 在底线命令模式中，基本的命令有（已经省略了冒号）： q 退出程序w 保存文件按ESC键可随时退出底线命令模式。 简单的说，我们可以将这三个模式想成底下的图标来表示： vim 按键说明第一部份：一般模式可用的光标移动、复制粘贴、搜索替换等 搜索替换 作用 /word 向光标之下寻找一个名称为 word 的字符串。例如要在档案内搜寻 vbird 这个字符串，就输入 /vbird 即可！ (常用) ?word 向光标之上寻找一个字符串名称为 word 的字符串。 n 这个 n 是英文按键。代表重复前一个搜寻的动作。举例来说， 如果刚刚我们执行 /vbird 去向下搜寻 vbird 这个字符串，则按下 n 后，会向下继续搜寻下一个名称为 vbird 的字符串。如果是执行 ?vbird 的话，那么按下 n 则会向上继续搜寻名称为 vbird 的字符串！ N 这个 N 是英文按键。与 n 刚好相反，为『反向』进行前一个搜寻动作。 例如 /vbird 后，按下 N 则表示『向上』搜寻 vbird 。 使用 /word 配合 n 及 N 是非常有帮助的！可以让你重复的找到一些你搜寻的关键词！ :n1,n2s/word1/word2/g n1 与 n2 为数字。在第 n1 与 n2 行之间寻找 word1 这个字符串，并将该字符串取代为 word2 ！举例来说，在 100 到 200 行之间搜寻 vbird 并取代为 VBIRD 则：:100,200s/vbird/VBIRD/g』。(常用) :1,$s/word1/word2/g 从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 ！(常用) :1,$s/word1/word2/gc 从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 ！且在取代前显示提示字符给用户确认 (confirm) 是否需要取代！(常用) 删除、复制与贴上 作用 x, X 在一行字当中，x 为向后删除一个字符 (相当于 [del] 按键)， X 为向前删除一个字符(相当于 [backspace] 亦即是退格键) (常用) nx n 为数字，连续向后删除 n 个字符。举例来说，我要连续删除 10 个字符， 『10x』。 dd 删除游标所在的那一整行(常用) ndd n 为数字。删除光标所在的向下 n 行，例如 20dd 则是删除 20 行 (常用) d1G 删除光标所在到第一行的所有数据 dG 删除光标所在到最后一行的所有数据 d$ 删除游标所在处，到该行的最后一个字符 d0 那个是数字的 0 ，删除游标所在处，到该行的最前面一个字符 yy 复制游标所在的那一行(常用) nyy n 为数字。复制光标所在的向下 n 行，例如 20yy 则是复制 20 行(常用) y1G 复制游标所在行到第一行的所有数据 yG 复制游标所在行到最后一行的所有数据 y0 复制光标所在的那个字符到该行行首的所有数据 y$ 复制光标所在的那个字符到该行行尾的所有数据 p, P p 为将已复制的数据在光标下一行贴上，P 则为贴在游标上一行！ 举例来说，我目前光标在第 20 行，且已经复制了 10 行数据。则按下 p 后， 那 10 行数据会贴在原本的 20 行之后，亦即由 21 行开始贴。但如果是按下 P 呢？ 那么原本的第 20 行会被推到变成 30 行。 (常用) J 将光标所在行与下一行的数据结合成同一行 c 重复删除多个数据，例如向下删除 10 行，[ 10cj ] u 复原前一个动作。(常用) [Ctrl]+r 重做上一个动作。(常用) 这个 u 与 [Ctrl]+r 是很常用的指令！一个是复原，另一个则是重做一次～ 利用这两个功能按键，你的编辑，嘿嘿！很快乐的啦！ . 不要怀疑！这就是小数点！意思是重复前一个动作的意思。 如果你想要重复删除、重复贴上等等动作，按下小数点『.』就好了！ (常用) 第二部份：一般模式切换到编辑模式的可用的按钮说明 进入输入或取代的编辑模式 作用 i, I 进入输入模式(Insert mode)：i 为『从目前光标所在处输入』， I 为『在目前所在行的第一个非空格符处开始输入』。 (常用) a, A 进入输入模式(Insert mode)：a 为『从目前光标所在的下一个字符处开始输入』， A 为『从光标所在行的最后一个字符处开始输入』。(常用) o, O 进入输入模式(Insert mode)：这是英文字母 o 的大小写。o 为『在目前光标所在的下一行处输入新的一行』； O 为在目前光标所在处的上一行输入新的一行！(常用) r, R 进入取代模式(Replace mode)：r 只会取代光标所在的那一个字符一次；R会一直取代光标所在的文字，直到按下 ESC 为止；(常用) 上面这些按键中，在 vi 画面的左下角处会出现『–INSERT–』或『–REPLACE–』的字样。 由名称就知道该动作了吧！！特别注意的是，我们上面也提过了，你想要在档案里面输入字符时， 一定要在左下角处看到 INSERT 或 REPLACE 才能输入喔！ [Esc] 退出编辑模式，回到一般模式中(常用) 第三部份：一般模式切换到指令行模式的可用的按钮说明 指令行的储存、离开等指令 指令行的储存、离开等指令 :w 将编辑的数据写入硬盘档案中(常用) :w! 若文件属性为『只读』时，强制写入该档案。不过，到底能不能写入， 还是跟你对该档案的档案权限有关啊！ :q 离开 vi (常用) :q! 若曾修改过档案，又不想储存，使用 ! 为强制离开不储存档案。注意一下啊，那个惊叹号 (!) 在 vi 当中，常常具有『强制』的意思～ :wq 储存后离开，若为 :wq! 则为强制储存后离开 (常用) ZZ 这是大写的 Z 喔！若档案没有更动，则不储存离开，若档案已经被更动过，则储存后离开！ :w [filename] 将编辑的数据储存成另一个档案（类似另存新档） :r [filename] 在编辑的数据中，读入另一个档案的数据。亦即将 『filename』 这个档案内容加到游标所在行后面 :n1,n2 w [filename] 将 n1 到 n2 的内容储存成 filename 这个档案。 :! command 暂时离开 vi 到指令行模式下执行 command 的显示结果！例如『:! ls /home』即可在 vi 当中察看 /home 底下以 ls 输出的档案信息！ vim 环境的变更 作用 :set nu 显示行号，设定之后，会在每一行的前缀显示该行的行号 :set nonu 与 set nu 相反，为取消行号！ vim 中批量添加注释方法一 ：块选择模式 批量注释： Ctrl + v 进入块选择模式，然后移动光标选中你要注释的行，再按大写的 I 进入行首插入模式输入注释符号如 // 或 #，输入完毕之后，按两下 ESC，Vim 会自动将你选中的所有行首都加上注释，保存退出完成注释。 取消注释： Ctrl + v 进入块选择模式，选中你要删除的行首的注释符号，注意 // 要选中两个，选好之后按 d 即可删除注释，ESC 保存退出。 方法二: 替换命令 批量注释。 使用下面命令在指定的行首添加注释。 使用名命令格式： :起始行号,结束行号s/^/注释符/g（注意冒号）。 取消注释： 使用名命令格式： :起始行号,结束行号s/^注释符//g（注意冒号）。 vim 多窗口使用技巧1、打开多个窗口打开多个窗口的命令以下几个： 横向切割窗口:new+窗口名(保存后就是文件名):split+窗口名，也可以简写为:sp+窗口名 纵向切割窗口名:vnew+窗口名(保存后就是文件名):vsplit+窗口名，也可以简写为：vsp+窗口名 2、关闭多窗口可以用：q!，也可以使用：close，最后一个窗口不能使用close关闭。使用close只是暂时关闭窗口，其内容还在缓存中，只有使用q!、w!或x才能真能退出。:tabc 关闭当前窗口:tabo 关闭所有窗口 3、窗口切换:ctrl+w+h/j/k/l，通过j/k可以上下切换，或者:ctrl+w加上下左右键，还可以通过快速双击ctrl+w依次切换窗口。 4、窗口大小调整纵向调整:ctrl+w + 纵向扩大（行数增加）:ctrl+w - 纵向缩小 （行数减少）:res(ize) num 例如：:res 5，显示行数调整为5行:res(ize)+num 把当前窗口高度增加num行:res(ize)-num 把当前窗口高度减少num行横向调整:vertical res(ize) num 指定当前窗口为num列:vertical res(ize)+num 把当前窗口增加num列:vertical res(ize)-num 把当前窗口减少num列 5、给窗口重命名:f file 6、vi打开多文件vi a b c:n 跳至下一个文件，也可以直接指定要跳的文件，如:n c，可以直接跳到c文件:e# 回到刚才编辑的文件 7、文件浏览:Ex 开启目录浏览器，可以浏览当前目录下的所有文件，并可以选择:Sex 水平分割当前窗口，并在一个窗口中开启目录浏览器:ls 显示当前buffer情况 8、vi与shell切换:shell 可以在不关闭vi的情况下切换到shell命令行:exit 从shell回到vi]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux SSH配置]]></title>
    <url>%2F2018%2F12%2F12%2FLinux-SSH%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Linux SSH配置什么是SSHSSH 为 Secure Shell 的缩写，由 IETF 的网络小组（Network Working Group）所制定；SSH 为建立在应用层基础上的安全协议。 SSH的作用专为远程登录会话和其他网络服务提供安全性的协议。 SSH的验证方式 基于口令的安全验证 只要你知道自己帐号和口令，就可以登录到远程主机。 基于密匙的安全验证 需要依靠密匙，也就是你必须为自己创建一对密匙，并把公用密匙放在需要访问的服务器上。 为什么要用密匙因为基于口令的验证，可能会有别的服务器在冒充真正的服务器，也就是受到“中间人”这种方式的攻击。而使用密钥的验证，需要加密所有传送的数据，而且“中间人”这种攻击方式也是不可能的（因为他没有你的私人密匙）。 如何配置 针对Linux 首先，配置SSH服务端 服务名一般是sshd linux 平台 查看sshd服务状态 1sudo systemctl status sshd 这代表启动成功 这代表启动失败 启动sshd服务 1sudo systemctl start sshd 关闭sshd服务 1sudo systemctl stop sshd 重启sshd服务 1sudo systemctl restart sshd 修改配置文件修改sshd服务的配置文件(通常):/etc/ssh/ssd_config使用vi/vim或nano都行 修改一下属性 ‘#’是注释去掉即可 123PubkeyAuthentication yes 开启密钥验证PermitEmptyPasswords yes 开启空密码PasswordAuthentication no 关闭口令验证(这里可选，如果自己只想密钥连接就修改) 接着，生成私钥与公钥一般在当前用户目录~ .ssh目录下 执行1ssh-keygen -t rsa 生成rsa 2048的密钥 然后，服务端保存生成的公钥这里以服务器本身做例子，一般用作远程。。。1234ssh-copy-id -i id_rsa yly@localhost-i 输出信息 id_rsa.pub 公钥文件(一般后缀名为*.pub 这里不需要后缀名)yly@localhost yly-&gt;用户名 localhost-&gt;本机地址 最后，连接服务器12ssh yly@localhost如果端口改变，只需在后面添加 -p 端口号 XShell5 做个例子,如何用密钥连接 首先生成密钥 借助ftp工具(推荐FileZilla)上传到服务器指定位置这里只上传了公钥 使用ssh-copy-id工具可能会添加错误，只需touch公钥一样名字的文件即可，不要.pub后缀]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[安装JDK]]></title>
    <url>%2F2018%2F12%2F12%2F%E5%AE%89%E8%A3%85JDK%2F</url>
    <content type="text"><![CDATA[安装JDK1.8需要准备Jdk1.8安装包 (32位或64位都行 其他版本也差不多)1. 开始安装 下一步 这里的安装路径默认即可，如果想要安装到其他路径，请注意不要出现中文路径 默认安装 2. 找到环境变量设置 什么是环境变量 一般是指在操作系统中用来指定操作系统运行环境的一些参数 环境变量的作用 要求系统运行一个程序而没有告诉它程序所在的完整路径时，系统除了在当前目录下面寻找此程序外，还应到path中指定的路径去找 两种方式可以进入设置 win + r 运行 control system 计算机右键属性 选择高级系统设置 选择环境变量 3. 设置环境变量这里选择系统变量 将会新建几个变量以及设置path 设置JAVA_HOME 设置CLASSPATH 设置PATH 这里可以新建 也可以在末尾添加 ;%JAVA_HOME%\bin;%JAVA_HOME%\jre\bin; (;和%是英文状态下的) ;是变量结束标志，而%是引用变量值 4. 验证JDK是否安装成功运行cmd 如果java和javac都有信息显示，则安装成功]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ubuntu 设置国内源]]></title>
    <url>%2F2018%2F12%2F12%2Fubuntu-%E8%AE%BE%E7%BD%AE%E5%9B%BD%E5%86%85%E6%BA%90%2F</url>
    <content type="text"><![CDATA[ubuntu 设置国内源为什么要设置源因为国内访问外网很慢，国内有许多镜像库，可以提高下载速度 设置源找到相对应版本的源 比如16.04 xenial 官方源 位置:/etc/apt/sources.list 我这里使用vim编辑器1sudo vim /etc/apt/sources.list 123456:1,$s/http:\/\/us.archive.ubuntu.com\/ubuntu\//http:\/\/mirrors.aliyun.com\/ubuntu\//g:1,$s/ -&gt; 这是从头到尾替换http:\/\/us.archive.ubuntu.com\/ubuntu\// -&gt; 这是原网址 \/ -&gt;这是转义后的/http:\/\/mirrors.aliyun.com\/ubuntu\/ -&gt; 替换网址/g -&gt; 替换时确认 1按回车键 enter 12:1,$s/http:\/\/security.ubuntu.com\/ubuntu/http:\/\/mirrors.aliyun.com\/ubuntu\//g 1:wq 更新缓存1sudo apt-get update]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F12%2F12%2FHello-World%2F</url>
    <content type="text"><![CDATA[希望通过这个博客，自己能够积累知识，提高学习能力。]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
</search>
